{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adrià Melús - 1527144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 3 d'APC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introducció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elon Musk és considerada la persona amb més diners del planeta actualment; és el director executiu de la empresa aerospacial SpaceX i de la d'automòvils elèctrics Tesla, i fa poc va rebre el títol de la persona del any per part de la revista Time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elon Musk també és algú que destaca per la seva activitat a Twitter, on publica memes o frases que deixen a tot el món pensant si realment les diu en serio. Mai està massa ocupat per comentar alguna broma o un pensament espontani. Tot i això, els seus intents per semblar graciós, per lo general acaben mosrant la seva irresponsabilitat al publicar tantes afirmacions confuses, insensibles o incorrectes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En honor al seu nou títol, que segons la publicació és otorgat a \"la persona o persones que més han afectat les notícies i les nostres vides, cap a bé o cap a malament\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest és l'informe de  l'anàlisi de resultats en aprenentatge computacional d'una base de dades de kaggle que conté més de 25.000 tweets d'Elon Musk: https://www.kaggle.com/taruntiwarihp/elon-musk-tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El propòsit principal d'aquest anàlisi és el de predir el sentiment d'un tweet segons sigui positiu o negatiu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/positive-negative.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following topics would be covered as an outline for this article:\n",
    "\n",
    "Data cleaning and preparation.\n",
    "Analysis of the data.\n",
    "Analysis and preprocessing text with NLTK.\n",
    "Resampling data.\n",
    "Model creation to predict sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLibreries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per aquest projecte haurem de instalar les seguents llibreries:\n",
    "\n",
    "Matplotlib, seaborn i wordcloud per la visualització gràfica de dades.\n",
    "\n",
    "Pandas i numpy pel tractament d'informació.\n",
    "\n",
    "SkLearn per l'entrenament dels nostres models.\n",
    "\n",
    "NLTK pel processament de text.\n",
    "\n",
    "imblearn pel \"resampling\" de la informació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4c447140bebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "# Import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import scikitplot as skplt\n",
    "import plotly.graph_objs as go\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from prettytable import PrettyTable\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "nltk.download('stopwords', quiet=True);\n",
    "nltk.download('vader_lexicon', quiet=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Informació de les dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer de tot observarem detalladament les dades i les entendrem. A continuació, si és necessari, netejarem el dataset i el prepararem per analitzar-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@elonmusk @realfuckingnews @business Ancient c...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets sentiment\n",
       "0  @elonmusk @realfuckingnews @business Ancient c...       pos"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar el Dataset\n",
    "\n",
    "dataset = \"../dataset/Elon Musk.csv\"\n",
    "dades = pd.read_csv(dataset)\n",
    "\n",
    "# Eliminem la primera columna perquè es tracta d'un index que no ens fa falta\n",
    "dades.drop(dades.columns[0], inplace = True, axis = 1)\n",
    "dades.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi ha 2 columnes i 25757 files.\n",
      "tweets       object\n",
      "sentiment    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Quantes files i columnes hi ha al dataset? Cada fila representa un tweet\n",
    "print(\"Hi ha {} columnes\".format(dades.shape[1]), \"i {} files.\".format(dades.shape[0]))\n",
    "print(dades.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot observar, aquest dataset conté 25757 files i 2 columnes. Cada fila correspon a un tweet i inclou dues variables:\n",
    "\n",
    "tweets: Variable de tipus object amb el contingut d'un tweet que cita @elonmusk.\n",
    "sentiment: Variable de tipus object que indica el sentiment del tweet. L'atribut sentiment pot prendre dos valors: pos (positiu) o neg (negatiu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara comprovarem si hi ha algun valor null o Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = dades.isnull().sum()\n",
    "null_counts[null_counts>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No s'ha trobat cap valor null o Nan, per tant no farà falta eliminar cap fila, de moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anàlisi de la informació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. (Distribució dels sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mètode d'aprenentatge computacional aplicat,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
